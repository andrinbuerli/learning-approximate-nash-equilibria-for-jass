{
 "timestamp": 1649334860,
 "log": {
  "projectname": "jass-mu-zero",
  "entity": "andrinburli",
  "group": "MuZero-MCTS-Experiment-1"
 },
 "agent": {
  "c_1": 1.25,
  "c_2": 19652,
  "dirichlet_alpha": 0.3,
  "dirichlet_eps": 0.25,
  "iterations": 50,
  "mdp_value": true,
  "discount": 1,
  "n_search_threads": 3,
  "virtual_loss": 10,
  "port": 9999,
  "temperature": 1.0,
  "threads_to_use": 4,
  "type": "mu-zero-mcts"
 },
 "optimization": {
  "optimizer": "adam",
  "learning_rate": 0.001,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "adam_epsilon": 1e-07,
  "batch_size": 32,
  "data_folder": "../results",
  "value_loss_weight": 0.25,
  "reward_loss_weight": 1.0,
  "policy_loss_weight": 1.0,
  "valid_policy_target": false,
  "use_per": false,
  "max_buffer_size": 20000,
  "min_buffer_size": 20000,
  "max_samples_per_episode": 512,
  "min_non_zero_prob_samples": 10000,
  "port": 8080,
  "store_model_weights_after": 10,
  "max_trajectory_length": 5,
  "min_trajectory_length": 5,
  "updates_per_step": 16,
  "iterations": 1000000,
  "weight_decay": 0.0001,
  "store_buffer": true,
  "log_n_steps_ahead": 15,
  "apa_n_games": 1
 },
 "network": {
  "action_space_size": 43,
  "fc_policy_layers": [
   256
  ],
  "fc_reward_layers": [
   256
  ],
  "fc_value_layers": [
   256
  ],
  "feature_extractor": "cnn-full",
  "num_blocks_representation": 4,
  "fcn_blocks_representation": 2,
  "num_blocks_dynamics": 4,
  "fcn_blocks_dynamics": 2,
  "num_blocks_prediction": 0,
  "num_channels": 128,
  "path": null,
  "players": 4,
  "reduced_channels_policy": 64,
  "reduced_channels_reward": 64,
  "reduced_channels_value": 64,
  "support_size": 157,
  "type": "resnet"
 }
}
